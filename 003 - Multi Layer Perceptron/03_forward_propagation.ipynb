{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47400f48-9b4b-4c46-ac19-61f20650c840",
   "metadata": {},
   "source": [
    "### Forward propagation\n",
    "\n",
    "Forward propagation is the process by which a neural network predicts output for a given input. It involves passing the input data through the network's layers, applying weights and biases, and activating neurons to produce an output. Here's how it works:\n",
    "\n",
    "1. **Input Layer**:\n",
    "   - The process begins with the input layer, where each neuron represents a feature of the input data. The input values are fed into the input neurons.\n",
    "\n",
    "2. **Weighted Sum and Bias**:\n",
    "   - Next, the input values are multiplied by weights and added together along with a bias term for each neuron in the first hidden layer.\n",
    "   - Mathematically, this is represented as:\n",
    "     $ z = w_1 \\cdot x_1 + w_2 \\cdot x_2 + \\ldots + w_n \\cdot x_n + b $\n",
    "   - Where:\n",
    "     - $ z $ is the weighted sum of inputs and biases.\n",
    "     - $ w_1, w_2, \\ldots, w_n $ are the weights associated with each input.\n",
    "     - $ x_1, x_2, \\ldots, x_n $ are the input values.\n",
    "     - $ b $ is the bias term.\n",
    "\n",
    "3. **Activation Function**:\n",
    "   - Once the weighted sum is computed, it's passed through an activation function, which introduces nonlinearity into the network.\n",
    "   - Common activation functions include sigmoid, tanh, ReLU, and softmax.\n",
    "   - The activation function determines whether and to what extent each neuron should be activated based on the weighted sum.\n",
    "   - The activated values are passed as inputs to the neurons in the next layer.\n",
    "\n",
    "4. **Propagation through Hidden Layers**:\n",
    "   - The process repeats for each hidden layer in the network. The output from the previous layer becomes the input to the next layer.\n",
    "   - At each hidden layer, the weighted sum is computed, passed through the activation function, and propagated to the next layer.\n",
    "\n",
    "5. **Output Layer**:\n",
    "   - Finally, the process continues until the data passes through all hidden layers and reaches the output layer.\n",
    "   - The output layer produces the final prediction or output of the neural network, which could be a single value (in regression tasks) or a probability distribution over classes (in classification tasks).\n",
    "   - The activation function used in the output layer depends on the task. For example, sigmoid or softmax activation functions are commonly used in binary or multi-class classification tasks, respectively.\n",
    "\n",
    "6. **Output Prediction**:\n",
    "   - The output produced by the output layer represents the neural network's prediction for the given input data.\n",
    "\n",
    "In summary, forward propagation involves passing input data through the network, computing weighted sums and biases, applying activation functions, and propagating the data through multiple layers to produce a prediction or output. It's a fundamental process in neural networks for making predictions based on input data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9aaaf51-f1ce-4d32-be65-2b84cf75137d",
   "metadata": {},
   "source": [
    "[Click here for Forward Propagation Maths](03_calculation.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
