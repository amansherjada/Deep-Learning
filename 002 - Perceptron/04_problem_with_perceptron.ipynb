{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0e925e3-e14d-47be-9f9a-69cf27dd570e",
   "metadata": {},
   "source": [
    "### Problems with perceptron\n",
    "\n",
    "The perceptron, while a fundamental building block in the history of neural networks, has several limitations and drawbacks, which have led to the development of more sophisticated models. Here are some of the main problems with perceptrons:\n",
    "\n",
    "1. **Limited to Linear Decision Boundaries**: The perceptron can only learn linear decision boundaries, meaning it can only classify data that is linearly separable. If the data is not linearly separable, the perceptron will fail to converge to a solution.\n",
    "\n",
    "    - Code: https://colab.research.google.com/drive/1x6detmf4WAUAT2pfdCts-dVrqnz4_gNB?usp=sharing\n",
    "\n",
    "2. **Inability to Handle Non-linear Data**: Many real-world datasets are inherently non-linear, and the perceptron's linear decision boundary may not be sufficient to accurately classify such data. Data with complex patterns or overlapping classes cannot be effectively separated by a single perceptron.\n",
    "\n",
    "    - Tool: https://playground.tensorflow.org/#activation=sigmoid&batchSize=10&dataset=xor&regDataset=reg-plane&learningRate=0.1&regularizationRate=0&noise=0&networkShape=&seed=0.33165&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false\n",
    "\n",
    "3. **Convergence Issues**: Even when the data is linearly separable, the perceptron learning algorithm may not converge to a solution if the learning rate is too high or if the data is noisy. In such cases, the weights may oscillate or diverge, preventing the perceptron from reaching a stable solution.\n",
    "\n",
    "4. **Single Layer Limitation**: Perceptrons are limited to a single layer of neurons, which means they cannot learn complex hierarchical representations of data. Many real-world tasks require capturing intricate relationships and dependencies in the data, which cannot be achieved by a single layer perceptron.\n",
    "\n",
    "5. **Binary Outputs**: The perceptron produces binary outputs (0 or 1) based on a threshold function, which may not be suitable for tasks requiring probabilistic outputs or multi-class classification.\n",
    "\n",
    "6. **Sensitivity to Initialization**: The performance of the perceptron learning algorithm can be highly sensitive to the initial weights. Depending on the initialization, the perceptron may converge to different solutions, leading to variability in performance.\n",
    "\n",
    "7. **Noisy Data**: The perceptron is sensitive to noise in the data, which can lead to misclassifications and degraded performance. Without robust mechanisms for handling noise, the perceptron may produce unreliable results on real-world datasets.\n",
    "\n",
    "While the perceptron laid the foundation for modern neural network models, these limitations prompted the development of more advanced architectures and learning algorithms, such as multi-layer perceptrons (MLPs), convolutional neural networks (CNNs), and recurrent neural networks (RNNs), which can overcome these challenges and achieve higher performance on a wide range of tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
