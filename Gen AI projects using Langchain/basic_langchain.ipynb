{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model = \"llama3\", temperature=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sher Mohammed Khan\\OneDrive\\Desktop\\Coding\\Python\\Langchain 2\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `BaseLLM.predict` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "text = \"What is the Capital of INDIA\"\n",
    "print(llm.predict(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sher Mohammed Khan\\OneDrive\\Desktop\\Coding\\Python\\Langchain 2\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEndpoint`.\n",
      "  warn_deprecated(\n",
      "c:\\Users\\Sher Mohammed Khan\\OneDrive\\Desktop\\Coding\\Python\\Langchain 2\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "llm_huggingface = HuggingFaceHub(repo_id=\"google/flan-t5-base\", model_kwargs={\"temperature\" : 0.6, \"max_length\": 64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delhi\n"
     ]
    }
   ],
   "source": [
    "output = llm_huggingface.predict(\"can you tell me the capital of India?\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love mumbai\n"
     ]
    }
   ],
   "source": [
    "output = llm_huggingface.predict(\"can you write a poem about mumbai\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "poem = llm.predict(\"can you write a poem about mumbai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Mumbai, city of dreams,\\nWhere the sun rises over the seas,\\nAnd the sounds of the streets never cease,\\nA symphony of life and energy.\\n\\nThe Gateway of India stands tall,\\nA monument to the city's grandeur all,\\nThe Arabian Sea laps at its feet,\\nAs the city's heartbeat skips a beat.\\n\\nIn the alleys of Bandra, you'll find,\\nStreet vendors selling spices so fine,\\nFresh from the markets of old Bombay,\\nFlavors that dance on the tongue, oh so merry.\\n\\nIn the streets of Colaba, you'll hear,\\nThe chatter of tourists, laughter so clear,\\nOf foreign tongues and curious eyes,\\nAs they take in the city's vibrant surprise.\\n\\nAt night, the lights of Marine Drive shine bright,\\nA crescent moon of twinkling delight,\\nThe Queen's Necklace, a sight to behold,\\nAs the stars align with the city's gold.\\n\\nIn the slums of Dharavi, you'll see,\\nResilience and hope, a testament to humanity,\\nThe people who call this city home,\\nTheir stories woven into the urban fabric, a tapestry so grand.\\n\\nMumbai, city of dreams,\\nWhere the impossible becomes possible, it seems,\\nA place where anything can happen, at any time,\\nWhere the rhythm of life is always on the rhyme.\\n\\nSo here's to Mumbai, our beloved town,\\nA city that never sleeps, nor slows down,\\nWhere the beauty lies in its chaotic charm,\\nAnd the magic happens, every single alarm.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What are Prompt Templates?**\n",
    "\n",
    "Prompt templates are predefined structures or frameworks used to generate consistent and effective prompts for language models like ChatGPT, Claude. They provide a standardized format for inputting information and instructions\n",
    "\n",
    "Prompt templates are like a recipe for generating text. They're a set of guidelines that help you create a specific type of text, like a product description or a social media post, by filling in the blanks with your own information.\n",
    "\n",
    "**Why use Prompt Templates?**\n",
    "\n",
    "Using prompt templates can save you time and effort when creating text. They help you:\n",
    "\n",
    "* Stay organized and focused\n",
    "* Ensure consistency in your writing style\n",
    "* Generate high-quality content quickly\n",
    "* Avoid writer's block\n",
    "\n",
    "**Example:**\n",
    "\n",
    "Let's say you want to write a social media post to announce a new product. You can use a prompt template like this:\n",
    "\n",
    "**Template:**\n",
    "\n",
    "\"Introducing [Product Name]! [Product Description] is now available for [Price]. Get [Benefits] and [Features] with our new [Product Category]. #NewProduct #MustHave\"\n",
    "\n",
    "**Fill-in-the-blank spaces:**\n",
    "\n",
    "* [Product Name]: Your product's name (e.g. \"SmartPhone X\")\n",
    "* [Product Description]: A brief summary of your product (e.g. \"A revolutionary smartphone with advanced camera features\")\n",
    "* [Price]: The price of your product (e.g. \"$499\")\n",
    "* [Benefits]: The benefits of your product (e.g. \"Take stunning photos and videos\")\n",
    "* [Features]: The key features of your product (e.g. \"Advanced camera, long-lasting battery, and sleek design\")\n",
    "* [Product Category]: The category your product belongs to (e.g. \"Smartphones\")\n",
    "\n",
    "**Example Output:**\n",
    "\n",
    "\"Introducing SmartPhone X! A revolutionary smartphone with advanced camera features is now available for $499. Get stunning photos and videos, long-lasting battery, and sleek design with our new Smartphones. #NewProduct #MustHave\"\n",
    "\n",
    "By using this prompt template, you can quickly create a social media post that's engaging, informative, and consistent with your brand's tone and style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me the Capital of India'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prompt Templates\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate(input_variables=[\"country\"], \n",
    "template=\"Tell me the Capital of {country}\")\n",
    "\n",
    "prompt_template.format(country = \"India\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sher Mohammed Khan\\OneDrive\\Desktop\\Coding\\Python\\Langchain 2\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n",
      "c:\\Users\\Sher Mohammed Khan\\OneDrive\\Desktop\\Coding\\Python\\Langchain 2\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delhi\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm = llm_huggingface, prompt= prompt_template)\n",
    "\n",
    "print(chain.run(\"India\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seqential Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_template = PromptTemplate(input_variables=[\"country\"], \n",
    "template=\"Please tell the capital of the {country}\")\n",
    "\n",
    "capital_chain = LLMChain(llm = llm, prompt=capital_template,\n",
    "output_key = \"capital\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "famous_template = PromptTemplate(input_variables=[\"capitapl\"],\n",
    "template=\"Suggest me some amazing place to visit in {capital}, give output considering only {capital}\")\n",
    "\n",
    "famous_chain = LLMChain(llm = llm_huggingface, prompt=famous_template, output_key=\"places\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "chain = SequentialChain(chains = [capital_chain, famous_chain],\n",
    "input_variables = [\"country\"],\n",
    "output_variables = [\"capital\", \"places\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sher Mohammed Khan\\OneDrive\\Desktop\\Coding\\Python\\Langchain 2\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'country': 'india',\n",
       " 'capital': 'The capital of India is New Delhi.',\n",
       " 'places': 'nehru'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain({\"country\": \"india\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chatmodels with ChatOpenAI, ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_llm = ChatGroq(temperature=0.6, model=\"llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000156965C7190>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000015696605BB0>, model_name='llama3-8b-8192', temperature=0.6, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sher Mohammed Khan\\OneDrive\\Desktop\\Coding\\Python\\Langchain 2\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Here are some comedy punchlines on life:\\n\\n1. \"I\\'m not saying life is short, but I\\'ve seen shorter lines at the DMV.\"\\n2. \"I love how we all pretend to be adults, but really we\\'re just grown-ups playing pretend.\"\\n3. \"Why do we have to grow up? Can\\'t we just stay in pajamas and eat cereal for breakfast?\"\\n4. \"I\\'m not arguing, I\\'m just explaining why I\\'m right. There\\'s a difference... or so I\\'ve been told.\"\\n5. \"Life is like a puzzle, except the pieces don\\'t fit together and the box is empty.\"\\n6. \"I\\'m not lazy, I\\'m just conserving energy... for Netflix.\"\\n7. \"Why do we have to get older? Can\\'t we just stay 25 and still have a fake ID?\"\\n8. \"I love how we all say \\'I\\'m a morning person\\', but really we\\'re just people who\\'ve learned to function on caffeine.\"\\n9. \"Life is like a game of Jenga, except instead of blocks, it\\'s our relationships and instead of a tower, it\\'s a mess.\"\\n10. \"I\\'m not saying I\\'m not responsible, but have you seen the price of avocado toast?\"\\n11. \"Why do we have to make New Year\\'s resolutions? Can\\'t we just make New Year\\'s excuses?\"\\n12. \"Life is like a book, except the ending is always \\'unexpected\\' and the plot is always \\'I have no idea what I\\'m doing\\'.\"\\n13. \"I love how we all pretend to be interested in other people\\'s hobbies, but really we\\'re just thinking \\'when\\'s the party?\\'\"\\n14. \"I\\'m not arguing, I\\'m just passionately expressing my point of view while completely dismissing yours.\"\\n15. \"Life is like a rollercoaster, except instead of thrills and excitement, it\\'s just a never-ending cycle of bills and responsibilities.\"\\n\\nHope these made you LOL!'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_llm([\n",
    "    SystemMessage(content=\"You are a Stand-Up comedian AI Assitant\"),\n",
    "    HumanMessage(content=\"Please provide some comedy punchlines on Life\")\n",
    "]).content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Template + Output Parser + LLM\n",
    "\n",
    "An Output Parser is a tool or method used to process and interpret the output generated by a system, such as a chatbot or any software program. It takes raw output and converts it into a more structured, understandable, or usable format.\n",
    "\n",
    "### Simple Example:\n",
    "\n",
    "Imagine you have a chatbot that provides weather information. When you ask for the weather, the chatbot might give you a raw output like this:\n",
    "\n",
    "```\n",
    "\"Today's weather: temp: 75F, humidity: 50%, condition: sunny\"\n",
    "```\n",
    "\n",
    "An Output Parser would take this raw output and convert it into a structured format that is easier to work with. For example:\n",
    "\n",
    "### Without Output Parser:\n",
    "```\n",
    "\"Today's weather: temp: 75F, humidity: 50%, condition: sunny\"\n",
    "```\n",
    "\n",
    "### With Output Parser:\n",
    "```python\n",
    "{\n",
    "    \"temperature\": \"75F\",\n",
    "    \"humidity\": \"50%\",\n",
    "    \"condition\": \"sunny\"\n",
    "}\n",
    "```\n",
    "\n",
    "### How It Works:\n",
    "\n",
    "1. **Raw Output:** The system generates an unstructured string of information.\n",
    "2. **Output Parser:** The parser processes this string, identifying key pieces of information.\n",
    "3. **Structured Output:** The parser converts the identified information into a structured format, like a dictionary or JSON object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Commaseperatedoutput(BaseOutputParser):\n",
    "    def parse(self, text:str):\n",
    "        return text.strip().split(\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " `text.strip().split(\",\")` This code is used to process a string, typically to remove any leading or trailing whitespace and then split the string into a list of substrings based on a specified delimiter (in this case, a comma).\n",
    "\n",
    "Explanation:\n",
    "\n",
    "1. **`text.strip()`**: This method removes any leading (spaces at the beginning) and trailing (spaces at the end) whitespace from the string `text`.\n",
    "\n",
    "2. **`.split(\",\")`**: This method splits the string into a list of substrings wherever there is a comma (`,`). Each substring is an element in the resulting list.\n",
    "\n",
    "- **`strip()`** removes whitespace from the start and end of the string.\n",
    "- **`split(\",\")`** breaks the string into a list using commas as separators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"Your are a helpful assistant. When the use given any input , you should generate 5 words synonyms in a comma seperated list\"\n",
    "human_template = \"{text}\"\n",
    "\n",
    "chatpromt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chatpromt | chat_llm | Commaseperatedoutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['monarch', ' ruler', ' sovereign', ' emperor', ' potentate']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\" : \"king\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bharat', ' Hindustan', ' Republic', ' Country', ' Nation']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\" : \"india\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4527b12d35ae819b8b3a55a337e35e08d4b45f8587a4dd01de691815ce4b4d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
